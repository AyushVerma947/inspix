{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rntJPk4H2OoF"
      },
      "source": [
        "# Download YouTube Video's Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCDAbzvU1DqZ",
        "outputId": "1cd2a72c-c03b-41ac-e08b-7e9c44c8efd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m51.2/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m784.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install pytube -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRT0zkiT1Q1L"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8F333t01vOK"
      },
      "outputs": [],
      "source": [
        "#VIDEO_URL = \"https://www.youtube.com/watch?v=hWLf6JFbZoo\" #obama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4s2ZtSmHj3-"
      },
      "outputs": [],
      "source": [
        "# VIDEO_URL = 'https://www.youtube.com/watch?v=H14bBuluwB8&pp=ygUGc3BlZWNo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZFSTWKDDBUx"
      },
      "outputs": [],
      "source": [
        "VIDEO_URL = 'https://www.youtube.com/watch?v=UF8uR6Z6KLc&pp=0gcJCcoJAYcqIYzv' #steve jobs 15 mins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9XZvTcI3mhz"
      },
      "outputs": [],
      "source": [
        "#VIDEO_URL = 'https://youtu.be/qNJRGHk7sN8'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhBsFZ4V1wZG"
      },
      "outputs": [],
      "source": [
        "yt = YouTube(VIDEO_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2neH9Hps4HDJ",
        "outputId": "84bb85ee-2287-41da-cca1-a1aa825a1087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/pytube/pytube\n",
            "  Cloning https://github.com/pytube/pytube to /tmp/pip-req-build-spkqo0hj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pytube/pytube /tmp/pip-req-build-spkqo0hj\n",
            "  Resolved https://github.com/pytube/pytube to commit a32fff39058a6f7e5e59ecd06a7467b71197ce35\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade git+https://github.com/pytube/pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP6ztmm34XRs"
      },
      "outputs": [],
      "source": [
        "# from pytube import YouTube\n",
        "# from moviepy.editor import AudioFileClip\n",
        "# import os\n",
        "\n",
        "\n",
        "# # get the first audio-only stream\n",
        "# stream = yt.streams.filter(only_audio=True).first()\n",
        "# download_path = stream.download(filename=\"ytaudio.mp4\")\n",
        "\n",
        "# print(\"Audio downloaded:\", download_path)\n",
        "\n",
        "# # ðŸ”¹ Step 2: Convert to MP3 using moviepy\n",
        "# mp3_filename = \"ytaudio.mp3\"\n",
        "\n",
        "# # load mp4 audio\n",
        "# audio_clip = AudioFileClip(download_path)\n",
        "# audio_clip.write_audiofile(mp3_filename)\n",
        "# audio_clip.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t9AFI4d6PAv",
        "outputId": "86277819-dd05-4656-e172-a688920814a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.9.5-py3-none-any.whl.metadata (177 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.9.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.9.5\n"
          ]
        }
      ],
      "source": [
        "pip install -U yt-dlp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q90_Ldvkgqs9"
      },
      "outputs": [],
      "source": [
        "# !pip install -U yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYwVyg1bhuVo"
      },
      "outputs": [],
      "source": [
        "# !yt-dlp --rm-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFuTwzMbh4YP"
      },
      "outputs": [],
      "source": [
        "# !yt-dlp -f best -o \"ytvideo.%(ext)s\" \"https://www.youtube.com/watch?v=H14bBuluwB8\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-Kq8EXQkweo",
        "outputId": "9e7c45d7-f54e-4e04-a9a7-b4cfe92fed3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.12/dist-packages (2025.9.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install yt-dlp --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmH18WL460QO",
        "outputId": "37cb0fee-8fe0-4eb5-a0c2-2ba0117ab6c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=lzILoMjEpaE&pp=ygUMc2hvcnQgc3BlZWNo\n",
            "[youtube] lzILoMjEpaE: Downloading webpage\n",
            "[youtube] lzILoMjEpaE: Downloading tv simply player API JSON\n",
            "[youtube] lzILoMjEpaE: Downloading tv client config\n",
            "[youtube] lzILoMjEpaE: Downloading player 0e6689e2-main\n",
            "[youtube] lzILoMjEpaE: Downloading tv player API JSON\n",
            "[info] lzILoMjEpaE: Downloading 1 format(s): 140-9\n",
            "[download] Destination: ytaudio.m4a\n",
            "\u001b[K[download] 100% of    1.09MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m1.82MiB/s\u001b[0m\n",
            "[FixupM4a] Correcting container of \"ytaudio.m4a\"\n"
          ]
        }
      ],
      "source": [
        "# download best audio in m4a container (mp4-style audio)\n",
        "# !yt-dlp -f \"bestaudio[ext=m4a]/bestaudio\" -o \"ytaudio.%(ext)s\" \"https://www.youtube.com/watch?v=UF8uR6Z6KLc&pp=0gcJCcoJAYcqIYzv\"\n",
        "!yt-dlp -f \"bestaudio[ext=m4a]/bestaudio\" -o \"ytaudio.%(ext)s\" \"https://www.youtube.com/watch?v=lzILoMjEpaE&pp=ygUMc2hvcnQgc3BlZWNo\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7rgLZU1hhJB"
      },
      "outputs": [],
      "source": [
        "# !yt-dlp -f \"bestaudio\" -o \"ytaudio.%(ext)s\" \"https://www.youtube.com/watch?v=UF8uR6Z6KLc\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk1w07V21XDZ"
      },
      "outputs": [],
      "source": [
        "# yt.streams \\\n",
        "#   .filter(only_audio = True, file_extension = 'mp4') \\\n",
        "#   .first() \\\n",
        "#   .download(filename = 'ytaudio')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUfk3DWo12yb"
      },
      "outputs": [],
      "source": [
        "# ! ffmpeg -i ytaudio.mp4 -acodec pcm_s16le -ar 16000 ytaudio.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU9eDLGl7i3O",
        "outputId": "2a437254-7744-48fa-92e1-0b2bded3a052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJmcvNMx7lX6",
        "outputId": "b8c27560-b715-4484-cdc6-1d2454565fc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Some of the most successful people in the world are the ones who've had the most failures. JK Rawlings, who wrote Harry Potter. Her first Harry Potter book was rejected 12 times before it was finally published. Michael Jordan was cut from his high school basketball team. He lost hundreds of games and missed thousands of shots during his career. But he once said, I have failed over and over and over again in my life, and that's why I succeed. These people succeeded because they understood that you can't let your failures define you. You have to let your failures teach you. You have to let them show you what to do differently the next time. So if you get into trouble, that doesn't mean you're a troublemaker. It means you need to try harder to add right. If you get a bad grade, that doesn't mean you're stupid. It just means you need to spend more time studying. No one's born being good at all things. You become good at things through hard work.\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"ytaudio.m4a\")\n",
        "print(result[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CqgQmI62RcX"
      },
      "source": [
        "# English ASR with HuggingSound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UkfBQrUN2Vjr"
      },
      "outputs": [],
      "source": [
        "# /!pip install huggingsound -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XkUnx8ZU2WlJ"
      },
      "outputs": [],
      "source": [
        "# from huggingsound import SpeechRecognitionModel\n",
        "# #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jj7WcGRx5NvJ"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cZYiuhenEtzD"
      },
      "outputs": [],
      "source": [
        "# device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2EisvBe52ZHO"
      },
      "outputs": [],
      "source": [
        "# model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\", device = device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX4o4edBE_7g"
      },
      "source": [
        "OUT OF MEMORY (OOM) error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqmMi7VMq3kq"
      },
      "source": [
        "# Audio Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "47leIDcR1LsQ"
      },
      "outputs": [],
      "source": [
        "# import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lm67x4AX3L57"
      },
      "outputs": [],
      "source": [
        "# input_file = '/content/ytaudio.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6NGzeYGr3IZA"
      },
      "outputs": [],
      "source": [
        "# print(librosa.get_samplerate(input_file))\n",
        "\n",
        "# # Stream over 30 seconds chunks rather than load the full file\n",
        "# stream = librosa.stream(\n",
        "#     input_file,\n",
        "#     block_length=30,\n",
        "#     frame_length=16000,\n",
        "#     hop_length=16000\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YmlYH6ag32bj"
      },
      "outputs": [],
      "source": [
        "# import soundfile as sf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Yj1wf18l3QJJ"
      },
      "outputs": [],
      "source": [
        "# for i,speech in enumerate(stream):\n",
        "#   sf.write(f'{i}.wav', speech, 16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oTMcAuRgH3DI"
      },
      "outputs": [],
      "source": [
        "# i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5H4Uyoy9jF9"
      },
      "source": [
        "# Audio Transcription / ASR / Speech to Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s8a8Mr4R6ndX"
      },
      "outputs": [],
      "source": [
        "# audio_path =[]\n",
        "# for a in range(i+1):\n",
        "#   audio_path.append(f'/content/{a}.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "spXDc1r88RPn"
      },
      "outputs": [],
      "source": [
        "# audio_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DYLKuZ1g2kmL"
      },
      "outputs": [],
      "source": [
        "# transcriptions = model.transcribe(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bbzcKziD9aYx"
      },
      "outputs": [],
      "source": [
        "# full_transcript = ' '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C2Vi7kXw2xGo"
      },
      "outputs": [],
      "source": [
        "# for item in transcriptions:\n",
        "#   full_transcript += ''.join(item['transcription'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2LKBXZrk5ima"
      },
      "outputs": [],
      "source": [
        "# len(full_transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FH8QJF3O9-IN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl6sG6LY-ibU"
      },
      "source": [
        "# Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jtmUwSt2-jj3"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wnxBQBAQ-u1B",
        "outputId": "9a4d2b1b-c365-4fb4-b2dd-cc81cd55d774"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "summarization = pipeline('summarization', model=\"Falconsai/text_summarization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8B_kTnByG2bY"
      },
      "outputs": [],
      "source": [
        "summarized_text = summarization(result[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aAwJDzf4IV4l",
        "outputId": "95a773a2-90c9-43b7-8460-ff3c97e09cdf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"JK Rawlings' first Harry Potter book was rejected 12 times before it was finally published . Michael Jordan was cut from his high school basketball team . They succeeded because they understood that you can't let your failures define you . You have to let them show you what to do differently the next time . It means you need to spend more time studying .\""
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarized_text[0]['summary_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2_Ypd125-GAU"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "import re\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    sentences = re.split(r'(?<=[\\.\\?\\!])\\s+', text)\n",
        "    return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "def chunk_text_by_tokens(text, tokenizer, max_tokens=512, min_sentences_per_chunk=1):\n",
        "    sentences = split_into_sentences(text)\n",
        "    chunks = []\n",
        "    cur = []\n",
        "    cur_tokens = 0\n",
        "\n",
        "    for sent in sentences:\n",
        "        sent_tokens = len(tokenizer.encode(sent, add_special_tokens=False))\n",
        "        if sent_tokens > max_tokens:\n",
        "            if cur:\n",
        "                chunks.append(\" \".join(cur))\n",
        "                cur = []\n",
        "                cur_tokens = 0\n",
        "            chunks.append(sent)\n",
        "            continue\n",
        "\n",
        "        if cur_tokens + sent_tokens > max_tokens and cur:\n",
        "            chunks.append(\" \".join(cur))\n",
        "            cur = [sent]\n",
        "            cur_tokens = sent_tokens\n",
        "        else:\n",
        "            cur.append(sent)\n",
        "            cur_tokens += sent_tokens\n",
        "\n",
        "    if cur:\n",
        "        chunks.append(\" \".join(cur))\n",
        "\n",
        "    if len(chunks) > 1 and len(split_into_sentences(chunks[-1])) < min_sentences_per_chunk:\n",
        "        chunks[-2] = chunks[-2] + \" \" + chunks[-1]\n",
        "        chunks.pop()\n",
        "    return chunks\n",
        "\n",
        "def summarize_long_text(text, model_name=\"Falconsai/text_summarization\",\n",
        "                        chunk_max_tokens=None, chunk_summary_max_length=200,\n",
        "                        final_summary_min_length=20, final_summary_max_length=40):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "    summarizer = pipeline(\"summarization\", model=model_name)\n",
        "\n",
        "    model_max = tokenizer.model_max_length if tokenizer.model_max_length and tokenizer.model_max_length < 10**6 else 512\n",
        "    if chunk_max_tokens is None:\n",
        "        chunk_max_tokens = int(model_max * 0.9)\n",
        "\n",
        "    chunks = chunk_text_by_tokens(text, tokenizer, max_tokens=chunk_max_tokens)\n",
        "\n",
        "    chunk_summaries = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        out = summarizer(chunk,\n",
        "                         max_length=chunk_summary_max_length,\n",
        "                         min_length=50,     # allow longer partial summaries\n",
        "                         do_sample=False,\n",
        "                         truncation=True)\n",
        "        chunk_text = out[0][\"summary_text\"]\n",
        "        chunk_summaries.append(chunk_text)\n",
        "\n",
        "    combined = \" \".join(chunk_summaries)\n",
        "    combined_tokens = len(tokenizer.encode(combined, add_special_tokens=False))\n",
        "    if combined_tokens > chunk_max_tokens:\n",
        "        final_out = summarizer(combined,\n",
        "                               max_length=final_summary_max_length,\n",
        "                               min_length=final_summary_min_length,\n",
        "                               do_sample=False,\n",
        "                               truncation=True)\n",
        "        final_summary = final_out[0][\"summary_text\"]\n",
        "    else:\n",
        "        final_summary = combined\n",
        "\n",
        "    return final_summary, chunk_summaries\n",
        "\n",
        "# Example usage:\n",
        "# summary, chunk_summaries = summarize_long_text(transcript)\n",
        "# print(\"20â€“30 word SUMMARY:\\n\", summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oBz3ocvg-fcS"
      },
      "outputs": [],
      "source": [
        "# summarized_text = summarization(result[\"text\"])\n",
        "full_transcript=result[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "We2NSA8S-HsH",
        "outputId": "74ae7572-03f0-4597-c474-90fd9c17c6f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FINAL SUMMARY:\n",
            " JK Rawlings' first Harry Potter book was rejected 12 times before it was finally published . Michael Jordan was cut from his high school basketball team . They succeeded because they understood that you can't let your failures define you . You have to let them show you what to do differently the next time . It means you need to spend more time studying .\n"
          ]
        }
      ],
      "source": [
        "summary, chunk_summaries = summarize_long_text(full_transcript, model_name=\"Falconsai/text_summarization\")\n",
        "print(\"FINAL SUMMARY:\\n\", summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5w0JiL_A_GAW",
        "outputId": "3d39e619-6480-4816-b614-2ef2ff13af60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "356"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4tP0q0wFARjw",
        "outputId": "5c88cfa8-86d4-4e16-8d58-c4d64f63bcf4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"JK Rawlings' first Harry Potter book was rejected 12 times before it was finally published . Michael Jordan was cut from his high school basketball team . They succeeded because they understood that you can't let your failures define you . You have to let them show you what to do differently the next time . It means you need to spend more time studying .\""
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ur0pMuYhAN5b",
        "outputId": "a2b50f1f-1559-4303-99a8-50f53977e459"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" Some of the most successful people in the world are the ones who've had the most failures. JK Rawlings, who wrote Harry Potter. Her first Harry Potter book was rejected 12 times before it was finally published. Michael Jordan was cut from his high school basketball team. He lost hundreds of games and missed thousands of shots during his career. But he once said, I have failed over and over and over again in my life, and that's why I succeed. These people succeeded because they understood that you can't let your failures define you. You have to let your failures teach you. You have to let them show you what to do differently the next time. So if you get into trouble, that doesn't mean you're a troublemaker. It means you need to try harder to add right. If you get a bad grade, that doesn't mean you're stupid. It just means you need to spend more time studying. No one's born being good at all things. You become good at things through hard work.\""
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ngn44TVnANZC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UKeGBA2X_I5G",
        "outputId": "d6b76217-eae4-48aa-8f31-1871dc16ca33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "956"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(result[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG4SklugG8rK"
      },
      "source": [
        "Text Chunking before Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "csrc1BT28RCZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QURSYAi6-oAG"
      },
      "outputs": [],
      "source": [
        "# num_iters = int(len(full_transcript)/1000)\n",
        "# summarized_text = []\n",
        "# for i in range(0, num_iters + 1):\n",
        "#   start = 0\n",
        "#   start = i * 1000\n",
        "#   end = (i + 1) * 1000\n",
        "#   #print(\"input text \\n\" + full_transcript[start:end])\n",
        "#   out = summarization(full_transcript[start:end], min_length = 5, max_length=20)\n",
        "#   out = out[0]\n",
        "#   out = out['summary_text']\n",
        "#  # print(\"Summarized text\\n\"+out)\n",
        "#   summarized_text.append(out)\n",
        "\n",
        "# #print(summarized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TuAHIrd5_Kmz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}